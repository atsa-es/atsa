---
title: "Stationarity & simple models"
subtitle: "FISH 507 â€“ Applied Time Series Analysis"
author: "Mark Scheuerell"
date: "10 Jan 2019"
output:
  ioslides_presentation:
    css: lecture_slides.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Topics for today

### Characteristics of time series (ts)
* Expectation, mean & variance
* Covariance & correlation
* Stationarity
* Autocovariance & autocorrelation
* Correlograms
* White noise
* Random walks
* Backshift & difference operators


## Expectation & the mean

The expectation (E) of a variable is its mean value in the population

$\text{E}(x) \equiv$ mean of $x = \mu$

Can estimate $\mu$ from a sample as

$$
\text{E}(x) = m = \frac{\sum_{i=1}^N{x_i}}{N}
$$


## Variance

$\text{E}([x - \mu]^2) \equiv$ mean deviations of $x$ about $\mu$

$\text{E}([x - \mu]^2) \equiv$ variance of $x = \sigma^2$

Can estimate $\sigma^2$ from a sample as

$$
\text{Var}(x) = s^2 = \frac{1}{N-1}\sum_{i=1}^N{(x_i - m)^2}
$$


## Covariance

If we have two variables, $x$ and $y$, we can generalize variance

$$
\text{Var}(x) = \text{E}([x_i - m]^2) = \text{E}([x_i - m][x_i - m])
$$

into _covariance_
 
$$
\text{Cov}(x,x) = \gamma(x,y) = \text{E}([x_i - m_x][y_i - m_y])
$$

Can estimate $\gamma(x,y)$ from a sample as

$$
\text{Cov}(x,y) = \frac{1}{N-1}\sum_{i=1}^N{(x_i - m_x)(y_i - m_y)}
$$










