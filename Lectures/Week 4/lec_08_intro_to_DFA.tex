% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  ignorenonframetext,
]{beamer}
\usepackage{pgfpages}
\setbeamertemplate{caption}[numbered]
\setbeamertemplate{caption label separator}{: }
\setbeamercolor{caption name}{fg=normal text.fg}
\beamertemplatenavigationsymbolsempty
% Prevent slide breaks in the middle of a paragraph
\widowpenalties 1 10000
\raggedbottom
\setbeamertemplate{part page}{
  \centering
  \begin{beamercolorbox}[sep=16pt,center]{part title}
    \usebeamerfont{part title}\insertpart\par
  \end{beamercolorbox}
}
\setbeamertemplate{section page}{
  \centering
  \begin{beamercolorbox}[sep=12pt,center]{part title}
    \usebeamerfont{section title}\insertsection\par
  \end{beamercolorbox}
}
\setbeamertemplate{subsection page}{
  \centering
  \begin{beamercolorbox}[sep=8pt,center]{part title}
    \usebeamerfont{subsection title}\insertsubsection\par
  \end{beamercolorbox}
}
\AtBeginPart{
  \frame{\partpage}
}
\AtBeginSection{
  \ifbibliography
  \else
    \frame{\sectionpage}
  \fi
}
\AtBeginSubsection{
  \frame{\subsectionpage}
}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\newif\ifbibliography
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Dynamic Factor Analysis},
  pdfauthor={Mark Scheuerell},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Dynamic Factor Analysis}
\subtitle{FISH 550 -- Applied Time Series Analysis}
\author{Mark Scheuerell}
\date{20 April 2023}

\begin{document}
\frame{\titlepage}

\begin{frame}{Topics for today}
\protect\hypertarget{topics-for-today}{}
Deterministic vs stochastic elements

Regression with autocorrelated errors

Regression with temporal random effects

Dynamic Factor Analysis (DFA)

\begin{itemize}
\item
  Forms of covariance matrix
\item
  Constraints for model fitting
\item
  Interpretation of results
\end{itemize}
\end{frame}

\begin{frame}{Code for today}
\protect\hypertarget{code-for-today}{}
You can find the R code for these lecture notes and other related
exercises \href{lec_08_intro_to_DFA.R}{here}.
\end{frame}

\begin{frame}{A very simple model}
\protect\hypertarget{a-very-simple-model}{}
Consider this simple model, consisting of a mean \(\mu\) plus error

\[
y_i = \mu + e_i ~ \text{with} ~ e_i \sim \text{N}(0,\sigma^2)
\]
\end{frame}

\begin{frame}{A very simple model}
\protect\hypertarget{a-very-simple-model-1}{}
The right-hand side of the equation is composed of \emph{deterministic}
and \emph{stochastic} pieces

\[
y_i = \underbrace{\mu}_{\text{deterministic}} + \underbrace{e_i}_{\text{stochastic}}
\]
\end{frame}

\begin{frame}{A very simple model}
\protect\hypertarget{a-very-simple-model-2}{}
Sometime these pieces are referred to as \emph{fixed} and \emph{random}

\[
y_i = \underbrace{\mu}_{\text{fixed}} + \underbrace{e_i}_{\text{random}}
\]
\end{frame}

\begin{frame}{A very simple model}
\protect\hypertarget{a-very-simple-model-3}{}
This can also be seen by rewriting the model

\[
y_i = \mu + e_i ~ \text{with} ~ e_i \sim \text{N}(0,\sigma^2)
\]

as

\[
y_i \sim \text{N}(\mu,\sigma^2)
\]
\end{frame}

\begin{frame}{Simple linear regression}
\protect\hypertarget{simple-linear-regression}{}
We can expand the deterministic part of the model, as with linear
regression

\[
y_i = \underbrace{\alpha + \beta x_i}_{\text{mean}} + e_i ~ \text{with} ~ e_i \sim \text{N}(0,\sigma^2)
\]

so

\[
y_i \sim \text{N}(\alpha + \beta x_i,\sigma^2)
\]
\end{frame}

\begin{frame}{A simple time series model}
\protect\hypertarget{a-simple-time-series-model}{}
Consider a simple model with a mean \(\mu\) plus white noise

\[
y_t = \mu + e_t ~ \text{with} ~ e_t \sim \text{N}(0,\sigma^2)
\]
\end{frame}

\begin{frame}{Time series model with covariates}
\protect\hypertarget{time-series-model-with-covariates}{}
We can expand the deterministic part of the model, as before with linear
regression

\[
y_t = \underbrace{\alpha + \beta x_t}_{\text{mean}} + e_t ~ \text{with} ~ e_t \sim \text{N}(0,\sigma^2)
\]

so

\[
y_t \sim \text{N}(\alpha + \beta x_t,\sigma^2)
\]
\end{frame}

\begin{frame}{Example of linear model}
\protect\hypertarget{example-of-linear-model}{}
\includegraphics{lec_08_intro_to_DFA_files/figure-beamer/ts_with_AR_errors-1.pdf}
\end{frame}

\begin{frame}{Model residuals}
\protect\hypertarget{model-residuals}{}
\includegraphics{lec_08_intro_to_DFA_files/figure-beamer/model_residuals-1.pdf}

These do \emph{not} look like white noise!
\end{frame}

\begin{frame}{ACF of model residuals}
\protect\hypertarget{acf-of-model-residuals}{}
\includegraphics{lec_08_intro_to_DFA_files/figure-beamer/ACF_model_residuals-1.pdf}

There is significant autocorrelation at lag = 1
\end{frame}

\begin{frame}{Model with autocorrelated errors}
\protect\hypertarget{model-with-autocorrelated-errors}{}
We can expand the stochastic part of the model to have autocorrelated
errors

\[
y_t = \alpha + \beta x_t + e_t \\
e_t = \phi e_{t-1} + w_t
\]

with \(w_t \sim \text{N}(0,\sigma^2)\)
\end{frame}

\begin{frame}{Model with autocorrelated errors}
\protect\hypertarget{model-with-autocorrelated-errors-1}{}
We can expand the stochastic part of the model to have autocorrelated
errors

\[
y_t = \alpha + \beta x_t + e_t \\
e_t = \phi e_{t-1} + w_t
\]

with \(w_t \sim \text{N}(0,\sigma^2)\)

We can write this model as our standard state-space model
\end{frame}

\begin{frame}{State-space model \textbar{} Observation equation}
\protect\hypertarget{state-space-model-observation-equation}{}
\[
\begin{align}
  y_t &= \alpha + \beta x_t + e_t \\
      &= e_t + \alpha + \beta x_t\\
      &\Downarrow \\
  y_t &= x_t + a + D d_t + v_t\\
\end{align}
\]

with

\(x_t = e_t\), \(a = \alpha\), \(D = \beta\), \(d_t = x_t\), \(v_t = 0\)
\end{frame}

\begin{frame}{State-space model \textbar{} State equation}
\protect\hypertarget{state-space-model-state-equation}{}
\[
\begin{align}
  e_t &= \phi e_{t-1} + w_t \\
      &\Downarrow \\
  x_t &= B x_t + w_t\\
\end{align}
\]

with

\(x_t = e_t\) and \(B = \phi\)
\end{frame}

\begin{frame}{State-space model \textbar{} Full form}
\protect\hypertarget{state-space-model-full-form}{}
\[
y_t = \alpha + \beta x_t + e_t \\
e_t = \phi e_{t-1} + w_t \\
\Downarrow \\
y_t = a + D d_t + x_t\\
x_t = B x_t + w_t
\]
\end{frame}

\begin{frame}[fragile]{State-space model \textbar{} Observation model in
\texttt{MARSS()}}
\protect\hypertarget{state-space-model-observation-model-in-marss}{}
\[
y_t = a + D d_t + x_t \\
\Downarrow \\
y_t = Z x_t + a + D d_t + v_t
\]

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y }\OtherTok{=}\NormalTok{ data         }\DocumentationTok{\#\# [1 x T] matrix of data}
\NormalTok{a }\OtherTok{=} \FunctionTok{matrix}\NormalTok{(}\StringTok{"a"}\NormalTok{)  }\DocumentationTok{\#\# intercept}
\NormalTok{D }\OtherTok{=} \FunctionTok{matrix}\NormalTok{(}\StringTok{"D"}\NormalTok{)  }\DocumentationTok{\#\# slope}
\NormalTok{d }\OtherTok{=}\NormalTok{ covariate    }\DocumentationTok{\#\# [1 x T] matrix of measured covariate}
\NormalTok{Z }\OtherTok{=} \FunctionTok{matrix}\NormalTok{(}\DecValTok{1}\NormalTok{)    }\DocumentationTok{\#\# no multiplier on x }
\NormalTok{R }\OtherTok{=} \FunctionTok{matrix}\NormalTok{(}\DecValTok{0}\NormalTok{)    }\DocumentationTok{\#\# v\_t \textasciitilde{} N(0,R); want v\_t = 0 for all t}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}[fragile]{State-space model \textbar{} State model in
\texttt{MARSS()}}
\protect\hypertarget{state-space-model-state-model-in-marss}{}
\[
x_t = B x_t + w_t \\
\Downarrow \\
x_t = B x_t + u + C c_t + w_t
\]

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{B }\OtherTok{=} \FunctionTok{matrix}\NormalTok{(}\StringTok{"b"}\NormalTok{)  }\DocumentationTok{\#\# AR(1) coefficient for model errors}
\NormalTok{Q }\OtherTok{=} \FunctionTok{matrix}\NormalTok{(}\StringTok{"q"}\NormalTok{)  }\DocumentationTok{\#\# w\_t \textasciitilde{} N(0,Q); var for model errors}
\NormalTok{u }\OtherTok{=} \FunctionTok{matrix}\NormalTok{(}\DecValTok{0}\NormalTok{)    }\DocumentationTok{\#\# u = 0}
\NormalTok{C }\OtherTok{=} \FunctionTok{matrix}\NormalTok{(}\DecValTok{0}\NormalTok{)    }\DocumentationTok{\#\# C = 0}
\NormalTok{c }\OtherTok{=} \FunctionTok{matrix}\NormalTok{(}\DecValTok{0}\NormalTok{)    }\DocumentationTok{\#\# c\_t = 0 for all t}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}{}
\protect\hypertarget{section}{}
MORE RANDOM EFFECTS
\end{frame}

\begin{frame}{Expanding the random effect}
\protect\hypertarget{expanding-the-random-effect}{}
Recall our simple model

\[
y_t = \underbrace{\mu}_{\text{fixed}} + \underbrace{e_t}_{\text{random}}
\]
\end{frame}

\begin{frame}{Expanding the random effect}
\protect\hypertarget{expanding-the-random-effect-1}{}
We can expand the random portion

\[
y_t = \underbrace{\mu}_{\text{fixed}} + ~ \underbrace{f_t + e_t}_{\text{random}}
\]

\[
e_t \sim \text{N}(0, \sigma) \\
f_t \sim \text{N}(f_{t-1}, \gamma)
\]
\end{frame}

\begin{frame}{Expanding the random effect}
\protect\hypertarget{expanding-the-random-effect-2}{}
We can expand the random portion

\[
y_t = \underbrace{\mu}_{\text{fixed}} + ~ \underbrace{f_t + e_t}_{\text{random}}
\]

\[
e_t \sim \text{N}(0, \sigma) \\
f_t \sim \text{N}(f_{t-1}, \gamma)
\]

This is simply a random walk observed with error
\end{frame}

\begin{frame}{Random walk observed with error}
\protect\hypertarget{random-walk-observed-with-error}{}
\[
y_t = \mu + f_t + e_t ~ \text{with} ~ e_t \sim \text{N}(0, \sigma) \\
f_t = f_{t-1} + w_t ~ \text{with} ~ w_t \sim \text{N}(0, \gamma) \\
\Downarrow \\
y_t = a + x_t + v_t ~ \text{with} ~ v_t \sim \text{N}(0, R) \\
x_t = x_{t-1} + w_t ~ \text{with} ~ w_t \sim \text{N}(0, Q)
\]
\end{frame}

\begin{frame}{Expanding fixed \& random effects}
\protect\hypertarget{expanding-fixed-random-effects}{}
We can expand the fixed portion

\[
y_t = \underbrace{\alpha + \beta x_t}_{\text{fixed}} + ~ \underbrace{f_t + e_t}_{\text{random}}
\]

\[
e_t \sim \text{N}(0, \sigma) \\
f_t \sim \text{N}(f_{t-1}, \gamma)
\]
\end{frame}

\begin{frame}{Fixed \& random effects \textbar{} In familiar state-space
form}
\protect\hypertarget{fixed-random-effects-in-familiar-state-space-form}{}
\[
y_t = \alpha + \beta x_t + f_t + e_t ~ \text{with} ~ e_t \sim \text{N}(0, \sigma) \\
f_t = f_{t-1} + w_t ~ \text{with} ~ w_t \sim \text{N}(0, \gamma) \\
\Downarrow \\
y_t = a + D d_t + x_t + v_t ~ \text{with} ~ v_t \sim \text{N}(0, R) \\
x_t = x_{t-1} + w_t ~ \text{with} ~ w_t \sim \text{N}(0, Q)
\]
\end{frame}

\begin{frame}{}
\protect\hypertarget{section-1}{}
MULTIPLE TIME SERIES
\end{frame}

\begin{frame}{Simple model for 2+ time series \textbar{} Random walk
observed with error}
\protect\hypertarget{simple-model-for-2-time-series-random-walk-observed-with-error}{}
\[
y_{i,t} = x_{i,t} + a_i + v_{i,t} \\
x_{i,t} = x_{i,t-1} + w_{i,t}
\]

with

\(v_{i,t} \sim \text{N}(0, R)\)

\(w_{i,t} \sim \text{N}(0, Q)\)
\end{frame}

\begin{frame}{Random walk observed with error}
\protect\hypertarget{random-walk-observed-with-error-1}{}
\[
y_{1,t} = x_{1,t} + a_1 + v_{1,t} \\
y_{2,t} = x_{2,t} + a_2 + v_{2,t} \\
\vdots \\
y_{n,t} = x_{n,t} + a_2 + v_{n,t} \\
\]

\[
x_{1,t} = x_{1,t-1} + w_{1,t} \\
x_{2,t} = x_{2,t-1} + w_{2,t} \\
\vdots \\
x_{n,t} = x_{n,t-1} + w_{n,t}
\]
\end{frame}

\begin{frame}{Random walk observed with error \textbar{} In matrix form}
\protect\hypertarget{random-walk-observed-with-error-in-matrix-form}{}
\[
\mathbf{y}_t = \mathbf{x}_t + \mathbf{a} + \mathbf{v}_t \\
\mathbf{x}_t = \mathbf{x}_{t-1} + \mathbf{w}_t
\]

with

\(\mathbf{v}_t \sim \text{MVN}(\mathbf{0}, \mathbf{R})\)

\(\mathbf{w}_t \sim \text{MVN}(\mathbf{0}, \mathbf{Q})\)
\end{frame}

\begin{frame}{}
\protect\hypertarget{section-2}{}
\begin{center}\includegraphics{lec_08_intro_to_DFA_files/figure-beamer/plot_many_ts-1} \end{center}
\end{frame}

\begin{frame}{Environmental time series}
\protect\hypertarget{environmental-time-series}{}
We often observe covariance among environmental time series, especially
for those collected close to one another in space
\end{frame}

\begin{frame}{}
\protect\hypertarget{section-3}{}
\begin{center}\includegraphics{lec_08_intro_to_DFA_files/figure-beamer/plot_many_ts_2-1} \end{center}

Are there some common patterns here?
\end{frame}

\begin{frame}{Common patterns in time series}
\protect\hypertarget{common-patterns-in-time-series}{}
\begin{center}\includegraphics{lec_08_intro_to_DFA_files/figure-beamer/plot_dfa_trends-1} \end{center}
\end{frame}

\begin{frame}{State-space model \textbar{} Ex: population structure}
\protect\hypertarget{state-space-model-ex-population-structure}{}
\[
\mathbf{y}_t = \mathbf{Z} \mathbf{x}_t + \mathbf{a} + \mathbf{v}_t \\
\mathbf{x}_t = \mathbf{x}_{t-1} + \mathbf{w}_t
\]

We can make (test) assumptions by specifying different forms for
\(\mathbf{Z}\)
\end{frame}

\begin{frame}{State-space model \textbar{} Ex: Harbor seal population
structure}
\protect\hypertarget{state-space-model-ex-harbor-seal-population-structure}{}
\[
\begin{bmatrix}
 y_1 \\
 y_2 \\
 y_3 \\
 y_4 \\
 y_5 
\end{bmatrix}_t =
\begin{bmatrix}
 1 & 0 & 0 \\
 0 & 1 & 0 \\
 0 & 1 & 0 \\
 0 & 0 & 1 \\
 0 & 0 & 1 \\
\end{bmatrix} \times
\begin{bmatrix}
 x_{JF} \\
 x_N \\
 x_S 
\end{bmatrix}_t +
\begin{bmatrix}
 a_1 \\
 a_2 \\
 a_3 \\
 a_4 \\
 a_5 
\end{bmatrix} +
\begin{bmatrix}
 v_1 \\
 v_2 \\
 v_3 \\
 v_4 \\
 v_5 
\end{bmatrix}_t
\]

\[
\begin{bmatrix}
 x_{JF} \\
 x_N \\
 x_S 
\end{bmatrix}_t =
\begin{bmatrix}
 x_{JF} \\
 x_N \\
 x_S 
\end{bmatrix}_{t-1} +
\begin{bmatrix}
 w_{JF} \\
 w_N \\
 w_S
\end{bmatrix}_t
\]
\end{frame}

\begin{frame}{Finding common patterns}
\protect\hypertarget{finding-common-patterns}{}
What if our observations were instead a mixture of 2+ states?

For example, we sampled haul-outs located between several breeding sites
\end{frame}

\begin{frame}{Mixtures of states}
\protect\hypertarget{mixtures-of-states}{}
\[
\begin{bmatrix}
 y_1 \\
 y_2 \\
 y_3 \\
 y_4 \\
 y_5 
\end{bmatrix}_t =
\begin{bmatrix}
 0.8 & 0.2 & 0 \\
 0.2 & 0.7 & 0.1 \\
 0 & 0.9 & 0.1 \\
 0 & 0.3 & 0.7 \\
 0 & 0.1 & 0.9 \\
\end{bmatrix} \times
\begin{bmatrix}
 x_{JF} \\
 x_N \\
 x_S 
\end{bmatrix}_t +
\begin{bmatrix}
 a_1 \\
 a_2 \\
 a_3 \\
 a_4 \\
 a_5 
\end{bmatrix} +
\begin{bmatrix}
 v_1 \\
 v_2 \\
 v_3 \\
 v_4 \\
 v_5 
\end{bmatrix}_t
\]

\[
\begin{bmatrix}
 x_{JF} \\
 x_N \\
 x_S 
\end{bmatrix}_t =
\begin{bmatrix}
 x_{JF} \\
 x_N \\
 x_S 
\end{bmatrix}_{t-1} +
\begin{bmatrix}
 w_{JF} \\
 w_N \\
 w_S
\end{bmatrix}_t
\]
\end{frame}

\begin{frame}{Finding common patterns}
\protect\hypertarget{finding-common-patterns-1}{}
What if our observations were a mixture of states, but we didn't know
how many or the weightings?

\[
\mathbf{y}_t = \mathbf{Z} \mathbf{x}_t + \mathbf{a} + \mathbf{v}_t \\
\mathbf{x}_t = \mathbf{x}_{t-1} + \mathbf{w}_t
\]

What are the dimensions of \(\mathbf{Z}\)?

What are the elements within \(\mathbf{Z}\)?
\end{frame}

\begin{frame}{Dynamic Factor Analysis (DFA)}
\protect\hypertarget{dynamic-factor-analysis-dfa}{}
DFA is a \emph{dimension reduction} technique, which models \(n\)
observed time series as a function of \(m\) hidden states (patterns),
where \(n \gg m\)
\end{frame}

\begin{frame}{Dynamic Factor Analysis (DFA) \textbar{} State-space form}
\protect\hypertarget{dynamic-factor-analysis-dfa-state-space-form}{}
\[
\mathbf{y}_t = \mathbf{Z} \mathbf{x}_t + \mathbf{a} + \mathbf{v}_t \\
\mathbf{x}_t = \mathbf{x}_{t-1} + \mathbf{w}_t
\]

data: \(\mathbf{y}_t\) is \(n \times 1\)

loadings: \(\mathbf{Z}\) is \(n \times m\) with \(n > m\)

states: \(\mathbf{x}_t\) is \(m \times 1\)
\end{frame}

\begin{frame}{Dimension reduction \textbar{} Principal Components
Analysis (PCA)}
\protect\hypertarget{dimension-reduction-principal-components-analysis-pca}{}
Goal is to reduce some large number of correlated variates into a few
uncorrelated factors
\end{frame}

\begin{frame}{Principal Components Analysis (PCA)}
\protect\hypertarget{principal-components-analysis-pca}{}
Calculating the principal components requires us to estimate the
covariance of the data

\[
\text{PC} = \text{eigenvectors}(\text{cov}(\mathbf{y}))
\]

There will be \(n\) principal components (eigenvectors) for an
\(n \times T\) matrix \(\mathbf{y}\)

We reduce the dimension by selecting a subset of the components that
explain much of the variance (eg, the first 2)
\end{frame}

\begin{frame}{Principal Components Analysis (PCA)}
\protect\hypertarget{principal-components-analysis-pca-1}{}
\includegraphics{lec_08_intro_to_DFA_files/figure-beamer/ex_corr_ts-1.pdf}
\end{frame}

\begin{frame}{Principal Components Analysis (PCA)}
\protect\hypertarget{principal-components-analysis-pca-2}{}
\includegraphics{lec_08_intro_to_DFA_files/figure-beamer/ex_PCA-1.pdf}
\end{frame}

\begin{frame}{Principal Components Analysis (PCA)}
\protect\hypertarget{principal-components-analysis-pca-3}{}
\includegraphics{lec_08_intro_to_DFA_files/figure-beamer/ex_PCA_rotated-1.pdf}
\end{frame}

\begin{frame}{Relationship between PCA \& DFA}
\protect\hypertarget{relationship-between-pca-dfa}{}
We need to estimate the covariance in the data \(\mathbf{y}\)

\[
\mathbf{y}_t = \mathbf{Z} \mathbf{x}_t + \mathbf{a} + \mathbf{v}_t, ~ \text{with} ~ \mathbf{v}_t \sim \text{MVN}(\mathbf{0}, \mathbf{R})
\]

so

\[
\text{cov}(\mathbf{y}_t) = \mathbf{Z} \text{cov}(\mathbf{x}_t) \mathbf{Z}^\top + \mathbf{R}
\] In PCA, we require \(\mathbf{R}\) to be diagonal, but not so in DFA
\end{frame}

\begin{frame}{Principal Components Analysis (PCA) \textbar{} Forms for
\(\mathbf{R}\) with \(n = 4\)}
\protect\hypertarget{principal-components-analysis-pca-forms-for-mathbfr-with-n-4}{}
\[
\mathbf{R} \stackrel{?}{=}
\begin{bmatrix}
 \sigma & 0 & 0 & 0 \\
 0 & \sigma & 0 & 0 \\
 0 & 0 & \sigma & 0 \\
 0 & 0 & 0 & \sigma
\end{bmatrix}
~\text{or}~~
\mathbf{R} \stackrel{?}{=}
\begin{bmatrix}
 \sigma_1 & 0 & 0 & 0 \\
 0 & \sigma_2 & 0 & 0 \\
 0 & 0 & \sigma_3 & 0 \\
 0 & 0 & 0 & \sigma_4
\end{bmatrix}
\]
\end{frame}

\begin{frame}{Dynamic Factor Analysis (DFA) \textbar{} Forms for
\(\mathbf{R}\) with \(n = 4\)}
\protect\hypertarget{dynamic-factor-analysis-dfa-forms-for-mathbfr-with-n-4}{}
\[
\mathbf{R} \stackrel{?}{=}
\begin{bmatrix}
 \sigma & 0 & 0 & 0 \\
 0 & \sigma & 0 & 0 \\
 0 & 0 & \sigma & 0 \\
 0 & 0 & 0 & \sigma
\end{bmatrix}
~\text{or}~~
\mathbf{R} \stackrel{?}{=}
\begin{bmatrix}
 \sigma_1 & 0 & 0 & 0 \\
 0 & \sigma_2 & 0 & 0 \\
 0 & 0 & \sigma_3 & 0 \\
 0 & 0 & 0 & \sigma_4
\end{bmatrix}
\]

\[
\mathbf{R} \stackrel{?}{=}
\begin{bmatrix}
 \sigma & \gamma & \gamma & \gamma \\
 \gamma & \sigma & \gamma & \gamma \\
 \gamma & \gamma & \sigma & \gamma \\
 \gamma & \gamma & \gamma & \sigma
\end{bmatrix}
~\text{or}~~
\mathbf{R} \stackrel{?}{=}
\begin{bmatrix}
 \sigma_1 & 0 & 0 & 0 \\
 0 & \sigma_2 & 0 & \gamma_{2,4} \\
 0 & 0 & \sigma_3 & 0 \\
 0 & \gamma_{2,4} & 0 & \sigma_4
\end{bmatrix}
\]
\end{frame}

\begin{frame}{Dynamic Factor Analysis (DFA)}
\protect\hypertarget{dynamic-factor-analysis-dfa-1}{}
\[
\mathbf{y}_t = \mathbf{Z} \mathbf{x}_t + \mathbf{a} + \mathbf{v}_t \\
\mathbf{x}_t = \mathbf{x}_{t-1} + \mathbf{w}_t
\]

What form should we use for \(\mathbf{Z}\)?

\[
\mathbf{Z} \stackrel{?}{=}
\begin{bmatrix}
 z_1 \\
 z_2 \\
 z_3 \\
 z_4 \\
 z_5
\end{bmatrix}
~\text{or}~~
\mathbf{Z} \stackrel{?}{=}
\begin{bmatrix}
 z_{1,1} & z_{2,1} \\
 z_{1,2} & z_{2,2} \\
 z_{1,3} & z_{2,3} \\
 z_{1,4} & z_{2,4} \\
 z_{1,5} & z_{2,5}
\end{bmatrix}
~\text{or}~~
\mathbf{Z} \stackrel{?}{=}
\begin{bmatrix}
 z_{1,1} & z_{2,1} & z_{3,1} \\
 z_{1,2} & z_{2,2} & z_{3,2} \\
 z_{1,3} & z_{2,3} & z_{3,3} \\
 z_{1,4} & z_{2,4} & z_{3,4} \\
 z_{1,5} & z_{2,5} & z_{3,5}
\end{bmatrix}
\]
\end{frame}

\begin{frame}{Dynamic Factor Analysis (DFA)}
\protect\hypertarget{dynamic-factor-analysis-dfa-2}{}
\[
\mathbf{y}_t = \mathbf{Z} \mathbf{x}_t + \mathbf{a} + \mathbf{v}_t \\
\mathbf{x}_t = \mathbf{x}_{t-1} + \mathbf{w}_t
\]

What form should we use for \(\mathbf{Z}\)?

\[
\mathbf{Z} \stackrel{?}{=}
\begin{bmatrix}
 z_1 \\
 z_2 \\
 z_3 \\
 \vdots \\
 z_5
\end{bmatrix}
~\text{or}~~
\mathbf{Z} \stackrel{?}{=}
\begin{bmatrix}
 z_{1,1} & z_{2,1} \\
 z_{1,2} & z_{2,2} \\
 z_{1,3} & z_{2,3} \\
 \vdots & \vdots \\
 z_{1,n} & z_{2,n}
\end{bmatrix}
~\text{or}~~
\mathbf{Z} \stackrel{?}{=}
\begin{bmatrix}
 z_{1,1} & z_{2,1} & z_{3,1} \\
 z_{1,2} & z_{2,2} & z_{3,2} \\
 z_{1,3} & z_{2,3} & z_{3,3} \\
 \vdots & \vdots & \vdots \\
 z_{1,n} & z_{2,n} & z_{3,n}
\end{bmatrix}
\]

We'll use model selection criteria to choose (eg, AICc)
\end{frame}

\begin{frame}{Fitting DFA models}
\protect\hypertarget{fitting-dfa-models}{}
Unless \(\mathbf{Z}\) is unconstrained in some manner, there are an
infinite number of combinations of \(\mathbf{Z}\) and \(\mathbf{x}\)
that will equal \(\mathbf{y}\)

Therefore we need to impose some constraints on the model
\end{frame}

\begin{frame}{Constraints on DFA models \textbar{} 1) The offset
\(\mathbf{a}\)}
\protect\hypertarget{constraints-on-dfa-models-1-the-offset-mathbfa}{}
\[
\mathbf{y}_t = \mathbf{Z} \mathbf{x}_t + \mathbf{a} + \mathbf{v}_t \\
\mathbf{x}_t = \mathbf{x}_{t-1} + \mathbf{w}_t
\]

\[
\mathbf{a} =
\begin{bmatrix}
 a_1 \\
 a_2 \\
 a_3 \\
 \vdots \\
 a_n
\end{bmatrix}
\]
\end{frame}

\begin{frame}{Constraints on DFA models \textbar{} 1) The offset
\(\mathbf{a}\)}
\protect\hypertarget{constraints-on-dfa-models-1-the-offset-mathbfa-1}{}
\[
\mathbf{y}_t = \mathbf{Z} \mathbf{x}_t + \mathbf{a} + \mathbf{v}_t \\
\mathbf{x}_t = \mathbf{x}_{t-1} + \mathbf{w}_t
\]

\[
\mathbf{a} =
\begin{bmatrix}
 a_1 \\
 a_2 \\
 a_3 \\
 \vdots \\
 a_n
\end{bmatrix}
\]

We will set the first \(m\) elements of \(\mathbf{a}\) to 0
\end{frame}

\begin{frame}{Constraints on DFA models \textbar{} 1) The offset
\(\mathbf{a}\)}
\protect\hypertarget{constraints-on-dfa-models-1-the-offset-mathbfa-2}{}
For example, if \(n = 5\) and \(m = 2\)

\[
\mathbf{a} =
\begin{bmatrix}
 a_1 \\
 a_2 \\
 a_3 \\
 a_4 \\
 a_5
\end{bmatrix}
\Rightarrow
\mathbf{a} =
\begin{bmatrix}
 0 \\
 0 \\
 a_3 \\
 a_4 \\
 a_5
\end{bmatrix}
\]
\end{frame}

\begin{frame}{Constraints on DFA models \textbar{} 1) The offset
\(\mathbf{a}\)}
\protect\hypertarget{constraints-on-dfa-models-1-the-offset-mathbfa-3}{}
For example, if \(n = 5\) and \(m = 2\)

\[
\mathbf{a} =
\begin{bmatrix}
 a_1 \\
 a_2 \\
 a_3 \\
 a_4 \\
 a_5
\end{bmatrix}
\Rightarrow
\mathbf{a} =
\begin{bmatrix}
 0 \\
 0 \\
 a_3 \\
 a_4 \\
 a_5
\end{bmatrix}
\Rightarrow
\mathbf{a} =
\begin{bmatrix}
 0 \\
 0 \\
 0 \\
 0 \\
 0
\end{bmatrix}
\]

Note, however, that this causes problems for the EM algorithm so we will
often de-mean the data and set \(a_i = 0\) for all \(i\)
\end{frame}

\begin{frame}{Constraints on DFA models \textbar{} 2) The loadings
\(\mathbf{Z}\)}
\protect\hypertarget{constraints-on-dfa-models-2-the-loadings-mathbfz}{}
\[
\mathbf{y}_t = \mathbf{Z} \mathbf{x}_t + \mathbf{a} + \mathbf{v}_t \\
\mathbf{x}_t = \mathbf{x}_{t-1} + \mathbf{w}_t
\]

\[
\mathbf{Z} =
\begin{bmatrix}
 z_{1,1} & z_{2,1} & \dots & z_{m,1} \\
 z_{1,2} & z_{2,2} & \dots & z_{m,2} \\
 z_{1,3} & z_{2,3} & \dots & z_{m,3} \\
 \vdots & \vdots & \ddots & z_{m,4} \\
 z_{1,n} & z_{2,n} & \dots & z_{m,n}
\end{bmatrix}
\]
\end{frame}

\begin{frame}{Constraints on DFA models \textbar{} 2) The loadings
\(\mathbf{Z}\)}
\protect\hypertarget{constraints-on-dfa-models-2-the-loadings-mathbfz-1}{}
\[
\mathbf{y}_t = \mathbf{Z} \mathbf{x}_t + \mathbf{a} + \mathbf{v}_t \\
\mathbf{x}_t = \mathbf{x}_{t-1} + \mathbf{w}_t
\]

\[
\mathbf{Z} =
\begin{bmatrix}
 z_{1,1} & z_{2,1} & \dots & z_{m,1} \\
 z_{1,2} & z_{2,2} & \dots & z_{m,2} \\
 z_{1,3} & z_{2,3} & \dots & z_{m,3} \\
 \vdots & \vdots & \ddots & z_{m,4} \\
 z_{1,n} & z_{2,n} & \dots & z_{m,n}
\end{bmatrix}
\]

We will set the upper right triangle of \(\mathbf{Z}\) to 0
\end{frame}

\begin{frame}{Constraints on DFA models \textbar{} 2) The loadings
\(\mathbf{Z}\)}
\protect\hypertarget{constraints-on-dfa-models-2-the-loadings-mathbfz-2}{}
For example, if \(n = 5\) and \(m = 3\)

\[
\mathbf{Z} =
\begin{bmatrix}
 z_{1,1} & 0 & 0 \\
 z_{1,2} & z_{2,2} & 0 \\
 z_{1,3} & z_{2,3} & z_{3,3} \\
 z_{1,4} & z_{2,3} & z_{3,4} \\
 z_{1,5} & z_{2,5} & z_{3,5}
\end{bmatrix}
\]

For the first \(m - 1\) rows of \(\mathbf{Z}\), \(z_{i,j} = 0\) if
\(j > i\)
\end{frame}

\begin{frame}{Constraints on DFA models \textbar{} 2) The loadings
\(\mathbf{Z}\)}
\protect\hypertarget{constraints-on-dfa-models-2-the-loadings-mathbfz-3}{}
An additional constraint is necessary in a Bayesian context

\[
\mathbf{Z} =
\begin{bmatrix}
 \underline{z_{1,1}} & 0 & 0 \\
 z_{1,2} & \underline{z_{2,2}} & 0 \\
 z_{1,3} & z_{2,3} & \underline{z_{3,3}} \\
 z_{1,4} & z_{2,3} & z_{3,4} \\
 z_{1,5} & z_{2,5} & z_{3,5}
\end{bmatrix}
\]

Diagonal of \(\mathbf{Z}\) is positive: \(z_{i,j} > 0\) if \(i = j\)
\end{frame}

\begin{frame}{Constraints on DFA models \textbar{} 3) The state variance
\(\mathbf{Q}\)}
\protect\hypertarget{constraints-on-dfa-models-3-the-state-variance-mathbfq}{}
\[
\mathbf{y}_t = \mathbf{Z} \mathbf{x}_t + \mathbf{a} + \mathbf{v}_t \\
\mathbf{x}_t = \mathbf{x}_{t-1} + \mathbf{w}_t
\]

\[
\mathbf{w}_t \sim \text{MVN}(\mathbf{0}, \mathbf{Q})
\]
\end{frame}

\begin{frame}{Constraints on DFA models \textbar{} 3) The state variance
\(\mathbf{Q}\)}
\protect\hypertarget{constraints-on-dfa-models-3-the-state-variance-mathbfq-1}{}
\[
\mathbf{y}_t = \mathbf{Z} \mathbf{x}_t + \mathbf{a} + \mathbf{v}_t \\
\mathbf{x}_t = \mathbf{x}_{t-1} + \mathbf{w}_t
\]

\[
\mathbf{w}_t \sim \text{MVN}(\mathbf{0}, \mathbf{Q})
\]

We will set \(\mathbf{Q}\) equal to the Identity matrix \(\mathbf{I}\)
\end{frame}

\begin{frame}{Constraints on DFA models \textbar{} 3) The state variance
\(\mathbf{Q}\)}
\protect\hypertarget{constraints-on-dfa-models-3-the-state-variance-mathbfq-2}{}
For example, if \(m = 4\)

\[
\mathbf{Q} =
\begin{bmatrix}
 1 & 0 & 0 & 0 \\
 0 & 1 & 0 & 0 \\
 0 & 0 & 1 & 0 \\
 0 & 0 & 0 & 1
\end{bmatrix}
\]

This allows our random walks to have a \emph{lot} of flexibility
\end{frame}

\begin{frame}{Dynamic Factor Analysis (DFA) \textbar{} Including \(p\)
covariates}
\protect\hypertarget{dynamic-factor-analysis-dfa-including-p-covariates}{}
\[
\mathbf{y}_t = \mathbf{Z} \mathbf{x}_t + \mathbf{a} + \underline{\mathbf{D} \mathbf{d}_t} + \mathbf{v}_t \\
\mathbf{x}_t = \mathbf{x}_{t-1} + \mathbf{w}_t
\]

\(\mathbf{d}_t\) is a \(p \times 1\) vector of covariates at time \(t\)

\(\mathbf{D}\) is an \(n \times p\) matrix of covariate effects
\end{frame}

\begin{frame}{Dynamic Factor Analysis (DFA) \textbar{} Form for
\(\mathbf{D}\)}
\protect\hypertarget{dynamic-factor-analysis-dfa-form-for-mathbfd}{}
\[
\mathbf{y}_t = \mathbf{Z} \mathbf{x}_t + \mathbf{a} + \underline{\mathbf{D}} \mathbf{d}_t + \mathbf{v}_t \\
\mathbf{x}_t = \mathbf{x}_{t-1} + \mathbf{w}_t
\]

Careful thought must be given \emph{a priori} as to the form for
\(\mathbf{D}\)

Should the effect(s) vary by site, species, etc?
\end{frame}

\begin{frame}{Dynamic Factor Analysis (DFA) \textbar{} Form for
\(\mathbf{D}\)}
\protect\hypertarget{dynamic-factor-analysis-dfa-form-for-mathbfd-1}{}
For example, given 2 covariates, \(\text{Temp}\) and \(\text{Salinity}\)

\[
\mathbf{D} =
\underbrace{
\begin{bmatrix}
 d_{\text{Temp}} & d_{\text{Salinity}} \\
 d_{\text{Temp}} & d_{\text{Salinity}} \\
 \vdots & \vdots \\
 d_{\text{Temp}} & d_{\text{Salinity}} \\
\end{bmatrix}
}_{\text{effects same by site/species}}
~~~ \text{or} ~~~
\mathbf{D} =
\underbrace{
\begin{bmatrix}
 d_{\text{Temp}, 1} & d_{\text{Salinity}, 1} \\
 d_{\text{Temp}, 2} & d_{\text{Salinity}, 2} \\
 \vdots & \vdots \\
 d_{\text{Temp}, n} & d_{\text{Salinity}, n} \\
\end{bmatrix}
}_{\text{effects differ by site/species}}
\]
\end{frame}

\begin{frame}{A note on model selection}
\protect\hypertarget{a-note-on-model-selection}{}
Earlier we saw that we could use model selection criteria to help us
choose among the different forms for \(\mathbf{Z}\)

However, caution must be given when comparing models with and without
covariates, and varying numbers of states
\end{frame}

\begin{frame}{A note on model selection}
\protect\hypertarget{a-note-on-model-selection-1}{}
Think about the DFA model form

\[
\mathbf{y}_t = \mathbf{Z} \underline{\mathbf{x}_t} + \mathbf{a} + \mathbf{D} \underline{\mathbf{d}_t} + \mathbf{v}_t \\
\]

\(\mathbf{x}_t\) are \emph{undetermined} random walks

\(\mathbf{d}_t\) are \emph{predetermined} covariates
\end{frame}

\begin{frame}{An example with 3 times series}
\protect\hypertarget{an-example-with-3-times-series}{}
Model 1 has 2 trends and no covariates

\[
\begin{bmatrix}
 y_1 \\
 y_2 \\
 y_3 
\end{bmatrix}_t =
\begin{bmatrix}
 z_{1,1} & z_{2,1} \\
 z_{1,2} & z_{2,2} \\
 z_{1,3} & z_{2,3}
\end{bmatrix}
\begin{bmatrix}
 x_1 \\
 x_2 
\end{bmatrix}_t +
\begin{bmatrix}
 v_1 \\
 v_2 \\
 v_3 
\end{bmatrix}_t
\]

Model 2 has 1 trend and 1 covariate

\[
\begin{bmatrix}
 y_1 \\
 y_2 \\
 y_3 
\end{bmatrix}_t =
\begin{bmatrix}
 z_1 \\
 z_2 \\
 z_3 
\end{bmatrix}
\begin{bmatrix}
 x
\end{bmatrix}_t +
\begin{bmatrix}
 D_1 \\
 D_2 \\
 D_3 
\end{bmatrix}
\begin{bmatrix}
 d
\end{bmatrix}_t +
\begin{bmatrix}
 v_1 \\
 v_2 \\
 v_3 
\end{bmatrix}_t
\]
\end{frame}

\begin{frame}{An example with 3 times series}
\protect\hypertarget{an-example-with-3-times-series-1}{}
Model 1 has 2 trends and no covariates

\[
\begin{bmatrix}
 y_1 \\
 y_2 \\
 y_3 
\end{bmatrix}_t =
\begin{bmatrix}
 z_{1,1} & z_{2,1} \\
 z_{1,2} & z_{2,2} \\
 z_{1,3} & z_{2,3}
\end{bmatrix}
\begin{bmatrix}
 x_1 \\
 x_2 
\end{bmatrix}_t +
\begin{bmatrix}
 v_1 \\
 v_2 \\
 v_3 
\end{bmatrix}_t
\]

Model 2 has 1 trend and 1 covariate

\[
\begin{bmatrix}
 y_1 \\
 y_2 \\
 y_3 
\end{bmatrix}_t =
\begin{bmatrix}
 z_1 \\
 z_2 \\
 z_3 
\end{bmatrix}
\begin{bmatrix}
 x
\end{bmatrix}_t +
\begin{bmatrix}
 D_1 \\
 D_2 \\
 D_3 
\end{bmatrix}
\begin{bmatrix}
 d
\end{bmatrix}_t +
\begin{bmatrix}
 v_1 \\
 v_2 \\
 v_3 
\end{bmatrix}_t
\]

Unless \(\mathbf{d}\) is \emph{highly correlated} with \(\mathbf{y}\),
Model 1 will be favored
\end{frame}

\begin{frame}{A note on model selection \textbar{} For models with
covariates}
\protect\hypertarget{a-note-on-model-selection-for-models-with-covariates}{}
\begin{itemize}
\item
  fit the \emph{most complex model you can envision} based on all of
  your possible covariates and random factors (states)
\item
  keep the covariates fixed and choose the number of trends (states)
  using AICc
\item
  keep the covariates \& states fixed and choose the form for
  \(\mathbf{R}\)
\item
  sort out the covariates while keeping the states \& \(\mathbf{R}\)
  fixed
\end{itemize}
\end{frame}

\begin{frame}{Interpreting DFA results}
\protect\hypertarget{interpreting-dfa-results}{}
Recall that we had to constrain the form of \(\mathbf{Z}\) to fit the
model

\[
\mathbf{Z} =
\begin{bmatrix}
 z_{1,1} & 0 & \dots & 0 \\
 z_{1,2} & z_{2,2} & \ddots & 0 \\
 \vdots & \vdots & \ddots & 0 \\
 \vdots & \vdots & \vdots & z_{m,m}  \\
 \vdots & \vdots & \vdots & \vdots \\
 z_{1,n} & z_{2,n} & z_{3,n} & z_{m,n} 
\end{bmatrix}
\]

So, the 1st common factor is determined by the 1st variate, the 2nd
common factor by the first two variates, etc.
\end{frame}

\begin{frame}{Interpreting DFA results}
\protect\hypertarget{interpreting-dfa-results-1}{}
To help with this, we can use a \emph{basis rotation} to maximize the
loadings on a few factors

If \(\mathbf{H}\) is an \(m \times m\) non-singular matrix, these 2 DFA
models are equivalent

\[
\mathbf{y}_t = \mathbf{Z} \mathbf{x}_t + \mathbf{a} + \mathbf{D} \mathbf{d}_t + \mathbf{v}_t \\
\mathbf{x}_t = \mathbf{x}_{t-1} + \mathbf{w}_t
\]

\[
\mathbf{y}_t = \mathbf{Z} \mathbf{H}^{-1} \mathbf{x}_t + \mathbf{a} + \mathbf{D} \mathbf{d}_t + \mathbf{v}_t \\
\mathbf{H} \mathbf{x}_t = \mathbf{H} \mathbf{x}_{t-1} + \mathbf{H} \mathbf{w}_t
\]

How should we choose \(\mathbf{H}\)?
\end{frame}

\begin{frame}{Basis rotation \textbar{} Varimax}
\protect\hypertarget{basis-rotation-varimax}{}
A \emph{varimax} rotation will maximize the variance of the loadings in
\(\mathbf{Z}\) along a few of the factors
\end{frame}

\begin{frame}{PCA of 5 wines with 8 attributes}
\protect\hypertarget{pca-of-5-wines-with-8-attributes}{}
\includegraphics{lec_08_intro_to_DFA_files/figure-beamer/ex_PCA_wines-1.pdf}
\end{frame}

\begin{frame}{Rotated loadings}
\protect\hypertarget{rotated-loadings}{}
\includegraphics{lec_08_intro_to_DFA_files/figure-beamer/ex_PCA_wines_rotated-1.pdf}
\end{frame}

\begin{frame}{Rotated loadings}
\protect\hypertarget{rotated-loadings-1}{}
\includegraphics{lec_08_intro_to_DFA_files/figure-beamer/ex_PCA_loadings-1.pdf}
\end{frame}

\begin{frame}{Topics for today}
\protect\hypertarget{topics-for-today-1}{}
Deterministic vs stochastic elements

Regression with autocorrelated errors

Regression with temporal random effects

Dynamic Factor Analysis (DFA)

\begin{itemize}
\item
  Forms of covariance matrix
\item
  Constraints for model fitting
\item
  Interpretation of results
\end{itemize}
\end{frame}

\end{document}
