---
title: "Homework #5 - Fitting DLMs"
subtitle: Answer Key
output:
  pdf_document:
    highlight: haddock
fontsize: 11pt
geometry: margin=1in
---

# Background 

Here are the answers for the homework problems on fitting Dynamic Linear Models (DLMs). We begin by getting the data, which have the following structure:

* `brood_yr`: the year the salmon were born
* `spawners`: number of spawners
* `recruits`: number of surviving offspring that "recruit" to the fishery
* `pdo_summer_t2`: PDO during first summer at sea
* `pdo_winter_t2`: PDO during first winter at sea

```{r get_data}
## get S-R data; cols are:
data(KvichakSockeye, package = "atsalibrary")
SR_data <- KvichakSockeye

## head of data file
head(SR_data)
```

The first few years of the data set have `NA` for the spawners, so we should remove those from the analysis.

```{r trim_spawners}
SR_data <- subset(SR_data, brood_year >= 1956)
```


# Question 1

Begin by fitting a reduced form of Equation (9.33) that includes only a time-varying level ($\alpha_t$) and observation error ($v_t$).  That is,

\begin{equation}
\begin{aligned}
\text{log}(R_t/S_t) &= \alpha_t + v_t \\
\alpha_t &= \alpha_{t-1} + w_t
\end{aligned}
\end{equation}

This model assumes no density-dependent survival in that the number of recruits is an ascending function of spawners.  Plot the ts of $\alpha_t$ and note the AICc for this model.  Also plot appropriate model diagnostics.

## Answer

The stock-recruit model here is a random walk observed with error, which we have seen a lot in class. To see the equivalency, instead write the observation model as

\begin{equation}
y_t = x_t + v_t
\end{equation}

where $y_t = \text{log}(R_t/S_t)$ and $x_t = \alpha_t$. The process model is then

\begin{equation}
x_t = x_{t-1} + w_t
\end{equation}

The first thing we need is to compute the response variable $y_t = \text{log}(R_t/S_t)$.

```{r compute_R_per_S}
## Time series of ln(R/S)
lnRS <- log(SR_data$recruits / SR_data$spawners)
dat <- matrix(lnRS, nrow = 1)
## number of years of data--we'll need this later
TT <- length(lnRS)
```

Now we can set up the DLM as a level-only model (i.e., a random walk with observation error) and fit it with MARSS.

```{r q1_marss, cache=TRUE}
library(MARSS)
## MARSS model defn
## for process eqn
BB <- matrix(1)
UU <- matrix(0)
QQ <- matrix("q")
## for observation eqn
ZZ <- matrix(1)
AA <- matrix(0)
RR <- matrix("r")
## only need starting values for regr parameters
inits_list <- list(x0 = matrix(1))
## list of model matrices & vectors
mod_list <- list(B = BB, U = UU, Q = QQ, Z = ZZ, A = AA, R = RR, tinitx = 0)
## fit DLM
Q1 <- MARSS(dat, inits = inits_list, model = mod_list)
## plot the time-varying level
plot.ts(t(Q1$states), ylab = expression(alpha[italic(t)]))
## get AICc
Q1$AICc
```

And finally examine some diagnostic plots:

```{r q1_kfss}
## get list of Kalman filter output
kf_out <- MARSS::MARSSkfss(Q1)
## forecast errors
innov <- kf_out$Innov
## Q-Q plot of forecast errors
qqnorm(t(innov), main = "", pch = 16, col = "blue")
## add y = x line for easier interpretation
qqline(t(innov))
## plot ACF of innovations
acf(t(innov), lag.max = 10, main = "ACF for Q1 residuals")
```

The residuals seem to be reasonably well behaved in that there appear normal with no significant autocorrelation.

# Question 2

Fit the full model specified by Equation (9.33).  For this model, obtain the time series of $\alpha_t$, which is an estimate of the stock productivity in the absence of density-dependent effects. How do these estimates of productivity compare to those from the previous question?  Plot the ts of $\alpha_t$ and note the AICc for this model.  Also plot appropriate model diagnostics.  ($Hint$: If you don't want a parameter to vary with time, what does that say about its process variance?)

\begin{equation}
\begin{aligned}
\text{log}(R_t/S_t) &= \alpha_t + b \text{log}(S_t) + v_t \\
\alpha_t &= \alpha_{t-1} + w_t
\end{aligned}
\end{equation}

## Answer

Now we need to fit a DLM with a time-varying level (intercept), but time-invariant slope. Begin by obtaining the time series of spawners to use as the covariate.

```{r create_sp_ts}
Sp <- matrix(SR_data$spawners, nrow = 1)
```

Set up the MARSS model structure so $\alpha$ varies with time, but not $\beta$, which means $q = 0$ for $\beta$. This means that $\mathbf{Q}$ should be

\begin{equation}
\mathbf{Q} = \begin{bmatrix}
    q_\alpha&0 \\
    0&0
    \end{bmatrix} 
\end{equation}

```{r q2_marss, cache = TRUE}
## number of regr coefs
m <- 2
## MARSS model defn
## for process eqn
B <- diag(m)                   ## 2x2; Identity
U <- matrix(0,nrow = m, ncol = 1)   ## 2x1; both elements = 0
Q <- matrix(list(0), m, m)       ## 2x2; all 0 for now
Q[1,1] <- "q_alpha"          	 ## 2x2; diag = (q1,q2)
## for observation eqn
Z <- array(NA, c(1, m, TT))   ## NxMxT; empty for now
Z[1,1,] <- rep(1, TT)        ## Nx1; 1's for intercept
Z[1,2,] <- Sp               ## Nx1; regr variable
A <- matrix(0)              ## 1x1; scalar = 0
R <- matrix("r")            ## 1x1; scalar = r
## only need starting values for regr parameters
inits_list <- list(x0 = matrix(c(0, 0), nrow = m))
## list of model matrices & vectors
mod_list <- list(B = B, U = U, Q = Q, Z = Z, A = A, R = R)
## list of control params
con_list <- list(maxit = 2000)
## fit DLM
Q2 <- MARSS(dat, inits = inits_list, model = mod_list, control = con_list)
## plot the time-varying level
plot.ts(Q2$states[1,], ylab = expression(alpha[italic(t)]))
```

Now let's check the AICc value.

```{r q2_aic}
## get AIC
Q2$AICc
```

The AICc value for this model is a bit higher than that for Q1.

Let's check out some diagnostic plots for the model in Q2. First we get the model innovations from our fitted `MARSS` object.

```{r q2_kfss}
## get list of Kalman filter output
kf_out <- MARSS::MARSSkfss(Q2)
## forecast errors
innov <- kf_out$Innov
```

```{r plot_Q2_diags}
## Q-Q plot of forecast errors
qqnorm(t(innov), main = "", pch = 16, col = "blue")
## add y = x line for easier interpretation
qqline(t(innov))
## plot ACF of innovations
acf(t(innov), lag.max = 10, main = "ACF for Q2 residuals")
```

The diagnostics indicate that there is some significant autocorrelation in the residuals at lags 5 & 10. The autocorrelation at lag 5 is likely a reflection of the dominant age classes of these fish.

# Question 3

Fit the model specified by Equation (9.34) with the summer PDO index as the covariate (`pdo_summer_t2`). What is the mean level of productivity?  Plot the ts of $\delta_t$ and note the AICc for this model.  Also plot appropriate model diagnostics.

\begin{equation}
\text{log}(R_t/S_t) = \alpha + \delta_t X_t - b \text{log}(S_t) + v_t \\
\delta_t = \delta_{t-1} + w_t
\end{equation}


## Answer

Now we need to fit a DLM so $\alpha$ and $\beta$ are time-invariant, but $\delta$ varies by year. This means that $\mathbf{Q}$ should be

\begin{equation}
\mathbf{Q} = \begin{bmatrix}
    0&0&0 \\
    0&0&0 \\
    0&0&q_\delta \end{bmatrix} 
 \end{equation}

```{r q3_marss, cache = TRUE}
## number of regr coefs
m <- 3
## MARSS model defn
## for process eqn
B <- diag(m) ## 2x2; Identity
U <- matrix(0, nrow = m, ncol = 1)
Q <- matrix(list(0), m, m)
## place delta last--it's the only one to time-vary
Q[3,3] <- ("q_delta")
## for observation eqn
Z <- array(NA, c(1, m, TT)) ## NxMxT; empty for now
Z[1,1,] <- rep(1, TT)  ## 1's for intercept
Z[1,2,] <- SR_data$spawners ## Sp regr variable
Z[1,3,] <- SR_data$pdo_summer_t2 ## summer PDO regr variable
A <- matrix(0) ## 1x1; scalar = 0
R <- matrix("r") ## 1x1; scalar = r
## only need starting values for regr parameters
inits_list <- list(x0 = matrix(c(0, 0, 0), nrow = m))
## list of model matrices & vectors
mod_list <- list(B = B, U = U, Q = Q, Z = Z, A = A, R = R)
## list of control params
con_list <- list(maxit = 2000, allow.degen = TRUE)
## fit DLM
Q3 <- MARSS(dat, inits = inits_list, model = mod_list, control = con_list)
## mean productivity
mean(Q3$states[1,])
## plot the time-varying effect of PDO
plot.ts(Q3$states[3,], ylab = expression(delta[italic(t)]))
```

Here, as in Q2, there does not appear to be any model support for a time-varying $\delta$.

```{r q3_aic}
## get AIC
Q3$AICc
```

Again, this model is no better than those in Q1 or Q2.

Here are some diagnostic plots:

```{r q3_kfss}
## get list of Kalman filter output
kf_out <- MARSS::MARSSkfss(Q3)
## forecast errors
innov <- kf_out$Innov
## Q-Q plot of forecast errors
qqnorm(t(innov), main = "", pch = 16, col = "blue")
## add y = x line for easier interpretation
qqline(t(innov))
## plot ACF of innovations
acf(t(innov), lag.max = 10, main = "ACF for Q3 residuals")
```

There is some indication that our model is not adequately accounting for autocorrelation in the residuals (i.e., significant correlation at lag = 1).

# Question 4

Fit the model specified by Equation (9.34) with the winter PDO index as the covariate (`pdo_winter_t2`). What is the mean level of productivity?  Plot the ts of $\delta_t$ and note the AICc for this model.  Also plot appropriate model diagnostics.

Again we need to fit a DLM so that $\alpha$ and $\beta$ are time-invariant, but $\delta$ varies by year. As for Q3, $\mathbf{Q}$ should be

\begin{equation}
\mathbf{Q} = \begin{bmatrix}
    0&0&0 \\
    0&0&0 \\
    0&0&q_\delta \end{bmatrix} 
 \end{equation}
  

```{r q4_marss, cache = TRUE}
## number of regr coefs
m <- 3
## MARSS model defn
## for process eqn
B <- diag(m) ## 2x2; Identity
U <- matrix(0,nrow = m, ncol = 1)
Q <- matrix(list(0), m, m)
## place delta last--it's the only one to time-vary
Q[3,3] <- ("q_delta")
## for observation eqn
Z <- array(NA, c(1, m, TT)) ## NxMxT; empty for now
Z[1,1,] <- rep(1, TT)  ## 1's for intercept
Z[1,2,] <- SR_data$spawners ## Sp regr variable
Z[1,3,] <- SR_data$pdo_winter_t2 ## winter PDO regr variable
A <- matrix(0) ## 1x1; scalar = 0
R <- matrix("r") ## 1x1; scalar = r
## only need starting values for regr parameters
inits_list <- list(x0 = matrix(c(0,0,0), nrow = m))
## list of model matrices & vectors
mod_list <- list(B = B, U = U, Q = Q, Z = Z, A = A, R = R)
## list of control params
con_list <- list(maxit = 2000, allow.degen = TRUE)
## fit DLM
Q4 <- MARSS(dat, inits = inits_list, model = mod_list, control = con_list)
## mean productivity
mean(Q4$states[1,])
## plot the time-varying effect of PDO
plot.ts(Q4$states[3,], ylab = expression(delta[italic(t)]))
```

Here it appears as though there is, in fact, some data support for a time-varying effect of PDO.

```{r q4_aic}
## get AIC
Q4$AICc
```

However, this model is not any better than that in Q1 or Q2.

Here are some diagnostic plots:

```{r q4_kfss}
## get list of Kalman filter output
kf_out <- MARSS::MARSSkfss(Q4)
## forecast errors
innov <- kf_out$Innov
## Q-Q plot of forecast errors
qqnorm(t(innov), main = "", pch = 16, col = "blue")
## add y = x line for easier interpretation
qqline(t(innov))
## plot ACF of innovations
acf(t(innov), lag.max = 10, main = "ACF for Q4 residuals")
```

As in Q3 there is some indication that our model is not adequately accounting for autocorrelation in the residuals (i.e., signficant correlation at lags 1 & 4-5).

# Question 5

Based on AICc, which of the models above is the most parsimonius?  Is it well behaved ($i.e.$, are the model assumptions met)?  Plot the model forecasts for the best model.  Is this a good forecast model?

Here is a table of AICc values for all 4 models.

```{r mod_selection}
tbl_aicc <- data.frame(model = paste0("Q",seq(4)),
                       AICc = round(c(Q1$AICc,Q2$AICc,Q3$AICc,Q4$AICc),1))
tbl_aicc
```

The model we fit in `r tbl_aicc$model[which.min(tbl_aicc$AICc)]` appears to have the lowest AIC, so let's use that for forecasting.

Here's how to obtain the time series of forecasts (and their SE) for the best model.

```{r q5_fore}
## get list of Kalman filter output
kf_out <- MARSS::MARSSkfss(Q1)
## forecasts of regr parameters; 2xT matrix
eta <- kf_out$xtt1
## predictor variable (1's only for the intercept)
Z <- array(1, c(1,1,TT))   ## NxMxT; empty for now
## ts of E(forecasts)
fore_mean <- vector()
for(t in 1:TT) {
  fore_mean[t] <- Z[,,t] %*% eta[,t,drop = F]
}
## variance of regr parameters; 1x2xT array
Phi <- kf_out$Vtt1
## obs variance; 1x1 matrix
R_est <- coef(Q1, type = "matrix")$R
## ts of Var(forecasts)
fore_var <- vector()
for(t in 1:TT) {
  tZ <- matrix(Z[,,t], 1, 1) ## transpose of Z
  fore_var[t] <- Z[,,t] %*% Phi[,,t] %*% tZ + R_est
}
```

And now we can plot them.

```{r q5_plots}
fup <- fore_mean + 2 * sqrt(fore_var)
flo <- fore_mean - 2 * sqrt(fore_var)
par(mar = c(4, 4, 0.1, 0), oma = c(0, 0, 2, 0.5))
ylims <- c(min(flo), max(fup))
plot(SR_data$brood_year, t(dat), type = "p", pch = 16, ylim = ylims,
     col = "blue", xlab = "Year", ylab = "ln(R/S") ##, xaxt = "n")
lines(SR_data$brood_year, fore_mean, type = "l", xaxt = "n", ylab = "", lwd = 3)
lines(SR_data$brood_year, fup)
lines(SR_data$brood_year, flo)
```

Overall, the accuracy of the forecasts is a bit suspect as many observations are at 0.5+ log-units from the forecast. Although most of the observed ln(R/S) fell within the 95% forecast intervals, the intervals themselves are relatively large and span a large range of R/S.